\begin{abstract}
While integrating tools like Code Interpreter and Search has significantly enhanced Large Language Model (LLM) reasoning in models like ChatGPT Agent and Gemini-Pro, practical guidance on optimal tool use is lacking. 
The core challenge is effectively combining textual reasoning, coding, and search for diverse questions. 
In this paper, we propose Tool-Use Mixture (\texttt{TUMIX}), an ensemble framework that runs multiple agents in parallel, each employing distinct tool-use strategies and answer paths. 
Agents in \texttt{TUMIX} iteratively share and refine responses based on the question and previous answers. 
In experiments, \texttt{TUMIX} achieves significant gains over state-of-the-art tool-augmented and test-time scaling methods, delivering an average accuracy improvement of up to 3.55\% over the best baseline on Gemini-2.5-Pro and Gemini-2.5-Flash across key reasoning benchmarks, with near-equal inference costs. 
We find that agent diversity and quality are crucial and can be enhanced by using LLMs to auto-optimize agent designs. 
Furthermore, \texttt{TUMIX} can halt refinement upon reaching sufficient confidence, preserving performance at only 49\% of the inference cost. Further scaling can achieve higher performance, albeit at a greater cost.




%Integrating tools like Code Interpreter and Search has significantly improved Large Language Models (LLMs) reasoning, as shown by leading models such as OpenAI's ChatGPT Agent and Google's Gemini-Pro. However, the research community still lacks practical guidance on fully leveraging these tools. The main challenge lies in finding an effective method to fully exploit the benefits of textual reasoning, coding, and searching when facing distinctive questions. To address this, we propose an ensemble-based framework that runs multiple agents in parallel, each exploring different answer paths with distinct tool-use strategies. Agents iteratively share and refine their answers by considering the original question and previous responses. Our proposed method Tool-Use Mixture (\texttt{TUMIX}) achieves significant gains over other state-of-the-art tool-augmented test-time scaling methods. With near equal inference costs, \texttt{TUMIX} delivers an average 3.55\% accuracy improvement over the best baseline on Gemini-2.5-Pro and Gemini-2.5-Flash across key reasoning benchmarks, where coding and search can effectively support reasoning when applied properly. We find that agent diversity and quality are crucial, and can be further improved by querying LLMs to automatically optimize agent designs. To reduce costs, \texttt{TUMIX} halts refinement once sufficient confidence is reached, preserving nearly the same performance at just 49\% of the inference cost. With further scaling, \texttt{TUMIX} can achieve even higher performance, though at substantially greater cost.
\end{abstract}